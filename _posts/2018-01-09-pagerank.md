---
title: Scalable Single Machine PageRank on 70M edge graph
date: 2018-01-09
thumb_img_path: "/images/pagerank.jpg"
content_img_path: ''
excerpt: Implementing a scalable PageRank algorithm using virtual memory on the LiveJournal
  graph network. PyPy was used to expedite the packing and unpacking functionality of Python.
layout: post
subtitle: Python, PyPy
canonical_url: ''
github: <a href="https://github.com/ashlitaylor/PageRank"  target="_blank" class="btn
  btn-primary">GitHub Repository</a> 

---
### Introduction
PageRank, named after Google co-founder Larry Page, is an algorithm that measures webpage importance. According to Google: 
>PageRank works by counting the number and quality of links to a page to determine a rough estimate of how important the website is. The underlying assumption is that more important websites are likely to receive more links from other websites
                                                               
The PageRank algorithm implemented in the pagerank.py code file can scale to graph datasets with as many as billions of edges and was implemented using my computer's virtual memory.
>The main idea is to place the dataset in your computer’s (unlimited) virtual memory, as it is often too big to fit in the RAM. When running algorithms on the dataset (e.g., PageRank), 
the operating system will automatically decide when to load the necessary data (subset of whole dataset) into RAM.

See [here]("http://poloclub.gatech.edu/mmap/") for more details on research on virtual memory mapping. The mapping for this algorithm is done using Python's [mmap]("https://docs.python.org/3/library/mmap.html) and [struct]("https://docs.python.org/2/library/struct.html") modules, and PyPy was used to expedite the packing and unpacking functionality of Python.
The PageRank algorithm was used on the [LiveJournal]("https://snap.stanford.edu/data/soc-LiveJournal1.html") graph, which contains almost 70 million edges.
The algorithm outputs the 10 nodes with the highest PageRank scores to a CSV file. 

### Prerequisites
This code requires ##Python 3.6** or later and uses PyPy, which is a Just-In-Time compilation runtime for Python, which supports fast packing and unpacking. You will also need to download the q1_utils.py code to the desired work folder. To install PyPy:

|OS |Instruction      |
|:----------|:-------------|
|Ubuntu |sudo apt-get install pypy|
|MacOS |Install [Homebrew](https://brew.sh/), then run brew install pypy3.|
|Windows |[Download](http://pypy.org/download.html#python2-7-compatible-pypy-5-4-1 ) the package and then install it. |

In the command line, run the following code from the q1_utils folder to learn more about the helper utility that was provided for this assignment.

```pypy q1_utils.py --help```
This code was specifically designed for use on the LieJournal graph dataset, which is an edge list file that can be obtained from the SNAP website here: [download](https://snap.stanford.edu/data/soc-LiveJournal1.html). The q1_utils.py and LiveJournal dataset files must be in the same directory/folder.

### The Code
```
import time
import mmap
from struct import unpack


"""
Below is code for the PageRank algorithm (power iteration).
Here, the binary index_file contains the mapping of each node's ID to its degree.
The node IDs range from 0 to max_node_id.
Hence, the index_file contains (max_node_id + 1) pairs of values,
each of which is of 'int' C type in little endian byte order.
The index_file is memory-mapped into the index_map object.
The binary edge_file contains the edges in the (source ID, target ID) format.
Hence, the edge_file contains edge_count pairs of values,
each of which is of 'int' C type in big endian byte order.
The edge_file is memory-mapped into the edge_map object.
My task was to determine the correct parameters needed to
(1) initialize the memory-mapped objects (index_map and edge_map),
(2) unpack the source and target IDs from the edge_map, and
(3) upack the source ID and source degree from the index_map.
This code assumes that the node IDs start from 0 and are contiguous up to max_node_id.
This algorithm returns the same scores as popular graph analysis libraries like NetworkX.
"""
def pagerank(index_file, edge_file, max_node_id, edge_count, damping_factor=0.85, iterations=10):
    index_map = mmap.mmap(
        index_file.fileno(),
        length= (max_node_id+1)*8,  
        access=mmap.ACCESS_READ)

    edge_map = mmap.mmap(
        edge_file.fileno(),
        length= edge_count * 8,  
        access=mmap.ACCESS_READ)

    scores = [1.0 / (max_node_id + 1)] * (max_node_id + 1)

    start_time = time.time()

    for it in range(iterations):
        new_scores = [0.0] * (max_node_id + 1)

        for i in range(edge_count):
            source, target = unpack(
                '>ii',  
                edge_map[i * 8: i * 8 + 8])  

            source_degree = unpack(
                '<ii',  
                index_map[source * 8: source * 8 + 8])[1]  

            new_scores[target] += damping_factor * scores[source] / source_degree

        min_pr = (1 - damping_factor) / (max_node_id + 1)
        new_scores = [min_pr + item for item in new_scores]
        scores = new_scores

        print ("Completed {0}/{1} iterations. {2} seconds elapsed." \
            .format(it + 1, iterations, time.time() - start_time))

    print ()

    return scores
```

### Run
To run the pagerank.py algorithm, follow the steps below. 
1. Since memory mapping works with binary files, the graph’s edge list needs to be converted into its binary format by running the following command at the terminal/command prompt (you only need to do this once):

    ```python q1_utils.py convert <path-to-edgelist.txt>```

    This generates 3 files:
    * A .bin binary file containing edges (source, target) in big-endian “int” C type
    * A .idx: binary file containing (node, degree) in little-endian “int” C type
    * A .json: metadata about the conversion process (required to run pagerank)

2. To execute the PageRank algorithm, type the following code into the command line/terminal:

    ```pypy q1_utils.py pagerank <path to JSON file for LiveJournal>```

    This will output the 10 nodes witht he highest PageRank scores. The default number of iterations is 10. The number of iterations can be updated by adding the desired number to the end of the command:
    ```pypy q1_utils.py pagerank toy-graph/toy-graph.json --iterations 25``
    A file in the format pagerank_nodes_n.txt  for “n” number of iterations will be created.
